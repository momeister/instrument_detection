import librosa
import numpy as np
import sys
from scipy.signal import find_peaks


sys.stdout.reconfigure(encoding='utf-8')

# Laden Sie die .wav-Datei

#audio_file = "Klänge/einstimmig-1-mp.mp3"
#audio_file = "Klänge/einstimmig-2-mp.mp3"
#audio_file = "Klänge\mehrstimmig-2.mp3"
audio_file = "Klänge\mehrstimmig-3.mp3"
#audio_file = "Klänge\mehrstimmig-4.mp3"

# Laden Sie das Musikstück und konvertieren Sie es in einen Konstant-Q-Chromagramm
y, sr = librosa.load(audio_file)
chromagram = librosa.feature.chroma_cqt(y=y, sr=sr)

def get_grundfrequenz(audio, sample_rate, start_time=0, duration=1):
    # Extrahieren des Audiosignals im angegebenen Zeitbereich
    start_sample = int(start_time * sample_rate)
    end_sample = start_sample + int(duration * sample_rate)
    audio_segment = audio[start_sample:end_sample]

    # Berechnen der FFT (Fast Fourier Transform) für das Audio-Segment
    fft_result = np.fft.fft(audio_segment)
    fft_magnitude = np.abs(fft_result)

    # Frequenzbereich definieren
    frequenzbereich = np.fft.fftfreq(len(fft_result), 1.0 / sample_rate)

    # Finden des Peaks (Grundfrequenz) im Frequenzspektrum
    grundfrequenz_index = np.argmax(fft_magnitude)
    grundfrequenz = frequenzbereich[grundfrequenz_index]

    # Nur positive Frequenzen und auf 3 Nachkommastellen runden
    grundfrequenz = round(abs(grundfrequenz), 3)

    return grundfrequenz

def get_half_frequency_intensity(audio_segment, sr, grundfrequenz):
    # Hälfte der Grundfrequenz
    half_frequency = grundfrequenz / 2

    # Berechnen Sie die FFT des Audiosegments
    D = np.abs(librosa.stft(audio_segment))
    freqs = librosa.fft_frequencies(sr=sr)

    # Ermitteln Sie den Index der Frequenz, der am nächsten an der halben Grundfrequenz liegt
    closest_freq_bin = np.argmin(np.abs(freqs - half_frequency))

    # Ermitteln Sie die durchschnittliche Intensität an diesem Frequenzindex
    intensity = np.mean(D[closest_freq_bin])

    return half_frequency, intensity

def instrument_analyze_for_one_instrument(intensity_data):
    # Zählen, wie oft jede Zahl im Array vorkommt
    counts = {i: intensity_data.count(i) for i in set(intensity_data)}

    # Überprüfen, ob das Array überwiegend 5en, 4en, 3en oder 2en enthält
    if counts.get(5, 0) >= len(intensity_data) / 2:
        return "Klavier"
    elif counts.get(4, 0) >= len(intensity_data) / 2:
        return "Oboe"
    elif counts.get(3, 0) >= len(intensity_data) / 2:
        return "Trompete"
    elif counts.get(2, 0) >= len(intensity_data) / 2:
        # Wenn viele 2en vorhanden sind, prüfen, ob auch 3en oder 4en signifikant sind
        if counts.get(3, 0) > 0 or counts.get(4, 0) > 0:
            if counts.get(4, 0) >= counts.get(3, 0):
                return "Oboe"
            else:
                return "Trompete"
        return "Violine"

    return "Nicht identifizierbar"

def instrument_analyze_for_multiple_instruments(intensity_data):
    # Definition der Instrumente mit ihren entsprechenden Zahlen
    instruments = {2: "Violine", 3: "Trompete", 4: "Oboe", 5: "Klavier"}

    # Zählen, wie oft jede Zahl im Array vorkommt
    counts = {i: intensity_data.count(i) for i in set(intensity_data)}

    # Gesamtanzahl der Elemente im Array
    total_elements = len(intensity_data)

    # Berechnung der Wahrscheinlichkeit für jedes Instrument
    probabilities = {instruments[num]: (counts.get(num, 0) / total_elements) * 100 for num in instruments}

    # Ausgabe der Instrumente und ihrer Wahrscheinlichkeiten
    for instrument, probability in probabilities.items():
        print(f"{instrument}: {probability:.2f}% wahrscheinlich")

    return probabilities

    
def check_other_dominant_frequencies(audio_segment, sr, grundfrequenz, intensity_threshold=1.00, freq_tolerance=5.0, frequency_to_tonart=None):
    D = np.abs(librosa.stft(audio_segment))
    freqs = librosa.fft_frequencies(sr=sr)

    all_potential_hints = []

    # Bestimmen Sie die dominanten Frequenzen im Spektrogramm
    mean_intensity = np.mean(D, axis=1)
    peaks, _ = find_peaks(mean_intensity, height=intensity_threshold)

    # Filtern Sie die Grundfrequenz und ihre Obertöne heraus
    dominant_frequencies = freqs[peaks]
    dominant_frequencies = [freq for freq in dominant_frequencies if freq > grundfrequenz * 1.1]

    # Zeigen Sie Hinweise für jede gefundene dominante Frequenz
    for freq in dominant_frequencies:
        hints = []
        complete_series = True  # Flag, um zu überprüfen, ob alle Obertöne vorhanden sind
        is_not_near_the_goundfreq = True

        # Fügen Sie die Grundfrequenz hinzu
        grund_intensity = mean_intensity[np.argmin(np.abs(freqs - freq))]
        hints.append((freq, grund_intensity))

        # Bestimmen der Tonart, wenn ein Mapping vorhanden ist
        tonart = frequency_to_tonart.get(freq) if frequency_to_tonart else "Unbekannt"

        # Berechnen Sie die Intensität der halben Grundfrequenz
        half_frequency, half_intensity = get_half_frequency_intensity(audio_segment, sr, freq)

        # Überprüfen, ob die halbe Frequenz eine hohe Intensität hat und nahe bei der neuen Grundfrequenz liegt       
        if half_intensity > 0.5 and abs(grundfrequenz - half_frequency) < freq_tolerance:
            # Die Bedingung ist erfüllt, geben Sie ein leeres Array zurück
            print(f"Die Hälfte der Frequenz {half_frequency} Hz mit Intensität {half_intensity} ist zu ähnlich zur Grundfrequenz {grundfrequenz} Hz.")
            is_not_near_the_goundfreq = False

        # Fügen Sie die Obertöne hinzu
        if is_not_near_the_goundfreq == True:
            for n in range(2, 16):  # Von 2 bis 15 für die Obertöne
                overtone_freq = freq * n
                if overtone_freq < freqs[-1]:  # Überprüfen Sie, ob der Oberton innerhalb des analysierten Frequenzbereichs liegt
                    closest_freq_bin = np.argmin(np.abs(freqs - overtone_freq))
                    intensity = mean_intensity[closest_freq_bin]
                    hints.append((overtone_freq, intensity))
                else:
                    complete_series = False
                    break  # Beenden Sie die Schleife, wenn der Oberton das Ende des Spektrums übersteigt

        # Fügen Sie diese Frequenz und ihre Obertöne nur hinzu, wenn alle Obertöne vorhanden sind
        if complete_series and len(hints) == 15 and is_not_near_the_goundfreq == True:
            all_potential_hints.append(hints)
            print(f"\nZusätzliche Tonart: {tonart}, Grundfrequenz: {freq:.2f} Hz mit Intensität {grund_intensity:.2f}")
            for overtone_freq, intensity in hints[1:]:
                print(f"Oberton: {overtone_freq:.2f} Hz mit Intensität {intensity:.2f}")
                
    return all_potential_hints

def check_fundamental_frequency_intensity(hint_list, tolerance=1e-2):
    fundamental_intensity = hint_list[0][1]
    overtone_intensities = [hint[1] for hint in hint_list[1:]]

    more_intense_overtone = any(fundamental_intensity < intensity for intensity in overtone_intensities if intensity > tolerance)
    complexity = sum(intensity > tolerance for intensity in overtone_intensities)
    higher_overtone_presence = sum(overtone_intensities[2:5]) > fundamental_intensity
    balanced_overtone_intensity = all(abs(overtone_intensities[i] - overtone_intensities[i+1]) < tolerance for i in range(len(overtone_intensities) - 1))
    total_overtone_intensity = sum(overtone_intensities) > fundamental_intensity

    # Prüft auf Klaviereigenschaften
    piano_like_properties = fundamental_intensity > max(overtone_intensities) and len([intensity for intensity in overtone_intensities if intensity > tolerance / 2]) > len(overtone_intensities) / 2

    if more_intense_overtone:
        return 3
    elif complexity > len(overtone_intensities) / 2:
        return 2
    elif higher_overtone_presence or balanced_overtone_intensity or total_overtone_intensity:
        return 4
    elif piano_like_properties:
        return 5  # Neue Kennzeichnung für Klaviereigenschaften
    else:
        return 1

# Zeitpunkte, an denen sich die Tonart ändert
tonartwechsel = np.where(np.diff(np.argmax(chromagram, axis=0)))[0]

# Endzeit wird hinzugefügt, da letzter Tonwechsel keinen neuen Wechsel besitzt
tonartwechsel = np.append(tonartwechsel, len(chromagram.T) - 1)

# Konvertiert Frames in Sekunden
time_points = librosa.frames_to_time(tonartwechsel, sr=sr)

print("timepoints: " , time_points)

# Tonart-Mapping (0=C, 1=C#, usw.)
tonart_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'H']

# Mindestdauer für einen Tonartwechsel (in Sekunden)
mindestdauer = 0.05

# Schwellenwert für die Grundfrequenz (in Hertz)
grundfrequenz_schwellenwert = 30.0

overtone_intensity_check_array = []

start_time = 0.0
previous_tonart_index = None  # Variable zur Verfolgung der vorherigen Tonart

freq_tolerance = 5.0 # Toleranz in Hz, Frequenzen innerhalb dieser Toleranz werden als gleich betrachtet

overtone_freq_array = []
intensity_array = []
potential_hints = []
previous_grundfrequenz = None 

for i in range(len(time_points)):
    end_time = time_points[i]

    if end_time - start_time >= mindestdauer:
        tonart_index = np.argmax(chromagram[:, tonartwechsel[i]])

        if tonart_index != previous_tonart_index:
            tonart = tonart_names[tonart_index]
            grundfrequenz = get_grundfrequenz(y, sr, start_time, 0.3)
            
            # Überspringe die aktuelle Frequenz, wenn sie der vorherigen ähnlich ist
            if previous_grundfrequenz is not None and abs(previous_grundfrequenz - grundfrequenz) <= freq_tolerance:
                continue
            
            audio_segment = y[int(start_time*sr):int(end_time*sr)]
            
            # Berechnen Sie das Spektrogramm D für das aktuelle Audiosegment
            D = np.abs(librosa.stft(audio_segment))

            current_grundfrequenz = grundfrequenz
            finding_lower_grundfrequenz = current_grundfrequenz

            while finding_lower_grundfrequenz > 30:
                # Ermitteln Sie die halbe Grundfrequenz und deren Intensität
                half_frequency, half_intensity = get_half_frequency_intensity(audio_segment, sr, finding_lower_grundfrequenz)

                # Überprüft, ob Intensität der halben Grundfrequenz über Schwellenwert liegt
                if half_intensity > 0.5:
                    current_grundfrequenz = half_frequency

                # Halbiert Frequenz um zu untersuchen, ob in unteren Bereichen mögliche hohe Intensitäten gefunden werden können
                finding_lower_grundfrequenz = finding_lower_grundfrequenz / 2
                    
                
            # Setzen Sie die endgültige Grundfrequenz
            grundfrequenz = current_grundfrequenz

            if grundfrequenz >= grundfrequenz_schwellenwert and grundfrequenz <= 4000:
                print(f"\nTonart {tonart} (Grundfrequnez: {grundfrequenz} Hz) von {start_time:.2f}s bis {end_time:.2f}s")
                
                grundton_intensität = None
                intensity_array_for_note = []

                # Zeige die ersten 15 Obertöne und deren Intensität basierend auf der neuen Grundfrequenz
                for n in range(1, 16):  # Oberton Nummer
                    overtone_freq = grundfrequenz * n
                    closest_freq_bin = np.argmin(np.abs(librosa.fft_frequencies(sr=sr) - overtone_freq))
                    intensity = np.mean(D[closest_freq_bin])
                    print(f"Oberton {n}: {overtone_freq:.2f} Hz, Intensität: {intensity:.2f}")
                    if n == 1 :
                        grundton_intensität = intensity
                    overtone_freq_array.append(overtone_freq)
                    intensity_array_for_note.append(intensity)
                    
                intensity_array.append(intensity_array_for_note)
                overtone_with_higher_intensity_found = False
                
                potential_hints.append(check_other_dominant_frequencies(audio_segment, sr, grundfrequenz))
                potential_hints = list(filter(None, potential_hints))
                
            previous_grundfrequenz = grundfrequenz  # Aktualisiere die vorherige Grundfrequenz

        previous_tonart_index = tonart_index
    start_time = end_time

# Teilen Sie overtone_freq_array in Unterlisten der Länge 15 (für jeden Satz von Obertönen)
sublists_overtone_freq = [overtone_freq_array[i:i + 15] for i in range(0, len(overtone_freq_array), 15)]

# Stellen Sie sicher, dass die Anzahl der Unterlisten in sublists_overtone_freq und intensity_array gleich ist
assert len(sublists_overtone_freq) == len(intensity_array), "Die Anzahl der Unterlisten stimmt nicht überein"

# Kombinieren Sie nun die Frequenzen und Intensitäten zu Tupeln
freq_and_intensity = [
    list(zip(freq_sublist, intensity_sublist))
    for freq_sublist, intensity_sublist in zip(sublists_overtone_freq, intensity_array)
]

for seperate_freq_and_intensity in freq_and_intensity: 
    overtone_intensity_check_array.append(check_fundamental_frequency_intensity(seperate_freq_and_intensity))

print("\nAlle nicht der Obertonreihe entsprechenden Frequenzen:")


more_than_one_instrument = False

if potential_hints:
    for hint_list in potential_hints:
        for hint_list_2 in hint_list:
            overtone_intensity_check_array.append(check_fundamental_frequency_intensity(hint_list_2))
            more_than_one_instrument = True

# Berechnen Sie die letzte Zeitspanne
if len(time_points) > 0:
    last_end_time = time_points[-1]
    if last_end_time - start_time >= mindestdauer:
        tonart_index = np.argmax(chromagram[:, tonartwechsel[-1]])

        if tonart_index != previous_tonart_index:
            # Ermitteln der dominierenden Frequenz
            frequency_bin = np.argmax(chromagram[:, tonartwechsel[-1]])
            midi_note = librosa.midi_to_note(frequency_bin)

            grundfrequenz = get_grundfrequenz(y, sr, start_time, mindestdauer)

            # Fügen Sie eine Bedingung hinzu, um Frequenzen über 4000 Hz zu ignorieren
            if grundfrequenz >= grundfrequenz_schwellenwert and grundfrequenz <= 4000:
                print(f"Tonart {tonart_names[tonart_index]} ({midi_note}) von {start_time:.2f}s bis {librosa.get_duration(y=y, sr=sr):.2f}s")

print(overtone_intensity_check_array)
            
# Ausgabe für ein Instrument
if not more_than_one_instrument:
    instrument = instrument_analyze_for_one_instrument(overtone_intensity_check_array)
    print(f"Das Instrument ist wahrscheinlich eine {instrument}.")
else:
    instrument_analyze_for_multiple_instruments(overtone_intensity_check_array)    
